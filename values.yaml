istio:
  # Specify the gateway and/or destinationHost or ignore if you pretend not to use. If the gateway
  # is deployed in a different namespace you must use the following format <namespace>/<gateway-name>.
  gateway: ""
  destinationHost: ""
  kibana:
    # Uncomment the field elastic-eck-stk.eck-kibana.config.server if you set to true.
    enabled: false
    ruleName: kibana-rule
    virtualServiceName: kibana-virtual-svc
    host: kibana-kb-http.observability.svc.cluster.local
    port: 5601
    # It must be the path defined in server.basePath and server.publicBaseUrl without the last slash.
    path: "/observability/kibana/"
  grafana:
    # Uncomment the field grafana."grafana.ini".server if you set to true.
    #
    # Set istio.destinationHost value in grafana.grafana.ini.server.domain
    enabled: false
    ruleName: grafana-rule
    virtualServiceName: grafana-virtual-svc
    host: grafana.observability.svc.cluster.local
    port: 8080
    # It must be the path defined in server.root_url without the last slash.
    path: "/observability/grafana/"

elastic-jg-stk:
  # Values:
  # - https://artifacthub.io/packages/helm/elastic/eck-stack/0.6.0
  # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/values.yaml
  #
  # Requires the ECK Operator: https://github.com/elastic/cloud-on-k8s/tree/main/deploy
  enabled: true
  eck-elasticsearch:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-elasticsearch/values.yaml
    enabled: true
    fullnameOverride: elasticsearch-jg-stk
    # Jaeger's Elasticsearch client doesn't support version 8.
    version: 7.17.11
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    http:
      service:
        spec:
          type: ClusterIP
      tls:
        selfSignedCertificate:
          disabled: true
    nodeSets:
      - name: masters
        count: 1
        config:
          node.roles: [ "master" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage
      - name: hot
        count: 1
        config:
          node.roles: [ "data_hot", "data_content", "ingest" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage
      - name: warm
        count: 1
        config:
          node.roles: [ "data_warm" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage
      - name: cold
        count: 1
        config:
          node.roles: [ "data_cold" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage

              # Unused components.
  eck-kibana:
    enabled: false
  eck-agent:
    enabled: false
  eck-fleet-server:
    enabled: false

jaeger-stack:
  # Values:
  # - https://artifacthub.io/packages/helm/jaegertracing/jaeger/0.71.7
  # - https://github.com/jaegertracing/helm-charts/blob/main/charts/jaeger/values.yaml
  #
  # Overall architecture with a brief explanation: https://www.jaegertracing.io/docs/1.46/architecture/
  enabled: true
  provisionDataStore:
    kafka: true
    cassandra: false
    elasticsearch: false
  fullnameOverride: jaeger-stack
  storage:
    type: elasticsearch
    elasticsearch:
      host: elasticsearch-jg-stk-es-http.observability.svc
      port: 9200
      user: elastic
      usePassword: true
      existingSecret: elasticsearch-jg-stk-es-elastic-user
      existingSecretKey: elastic
      tls:
        enabled: false
    kafka:
      brokers:
        - kafka-tracing.observability.svc:9092
      topic: jaeger-tracing
      authentication: none

  # Used as an offloader in cases which the throughput of traces is higher.
  kafka:
    # Values:
    # - https://artifacthub.io/packages/helm/bitnami/kafka/19.1.5
    # - https://github.com/bitnami/charts/tree/main/bitnami/kafka
    fullnameOverride: kafka-tracing
    image:
      registry: docker.io
      repository: bitnami/kafka
      tag: 3.3.1-debian-11-r19
    replicaCount: 1
    livenessProbe:
      enabled: true
      initialDelaySeconds: 60
      timeoutSeconds: 5
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
    readinessProbe:
      enabled: true
      initialDelaySeconds: 50
      failureThreshold: 6
      timeoutSeconds: 5
      periodSeconds: 10
      successThreshold: 1
    podAnnotations:
      sidecar.istio.io/inject: "false"
    autoCreateTopicsEnable: true
    persistence:
      enabled: true
      # Adjust to your storage class name.
      # storageClass: local-storage
      accessModes: [ "ReadWriteOnce" ]
      size: 1Gi
      logPersistence:
        enabled: false
        # Adjust to your storage class name.
        # storageClass: local-storage
        accessModes: [ "ReadWriteOnce" ]
        size: 1Gi
    zookeeper:
      # Values:
      # - https://artifacthub.io/packages/helm/bitnami/zookeeper/10.2.5
      # - https://github.com/bitnami/charts/tree/main/bitnami/zookeeper
      enabled: true
      image:
        registry: docker.io
        repository: bitnami/zookeeper
        tag: 3.8.0-debian-11-r56
      fullnameOverride: zookeeper-kafka-tracing
      replicaCount: 1
      livenessProbe:
        enabled: true
        initialDelaySeconds: 40
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 6
        successThreshold: 1
        probeCommandTimeout: 2
      readinessProbe:
        enabled: true
        initialDelaySeconds: 30
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 6
        successThreshold: 1
        probeCommandTimeout: 2
      podAnnotations:
        sidecar.istio.io/inject: "false"
      persistence:
        enabled: true
        accessModes: [ "ReadWriteOnce" ]
        size: 1Gi
        dataLogDir:
          size: 200Mi

  # Injests traces from Kafka to the storage backend (i.e., Elasticsearch).
  injester:
    enabled: true
    replicaCount: 1
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 2
      behavior:
        targetCPUUtilizationPercentage: 80
        targetMemoryUtilizationPercentage: 80
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
    podAnnotations:
      sidecar.istio.io/inject: "false"

  agent:
    # OpenTelemetry Collectors are used as span injestors.
    # Actually, this is deprecated...
    enabled: false

  # Recieves traces and publishes them in Kafka.
  collector:
    enabled: true
    image: jaegertracing/jaeger-collector
    tag: 1.45.0
    replicaCount: 1
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 2
    service:
      type: ClusterIP
      otlp:
        grpc:
          name: otlp-grpc
          port: 4317
        http:
          name: otlp-http
          port: 4318
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
    podAnnotations:
      sidecar.istio.io/inject: "false"

  # Tracer viewer (with Jaeger UI included).
  # Know more here: https://www.jaegertracing.io/docs/1.6/deployment/#query-service--ui
  query:
    enabled: true
    image: jaegertracing/jaeger-query
    tag: 1.45.0
    agentSidecar:
      enabled: false
    replicaCount: 1
    service:
      type: ClusterIP
      port: 8080
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 256m
        memory: 128Mi
    podAnnotations:
      sidecar.istio.io/inject: "false"

  # Kind of a garbage collector.
  esIndexCleaner:
    enabled: true
    extraEnv:
      - name: ROLLOVER
        value: 'true'
      # Format: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#schedule-syntax
    schedule: "55 23 * * *"
    successfulJobsHistoryLimit: 3
    failedJobsHistoryLimit: 3
    concurrencyPolicy: Forbid
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 256m
        memory: 128Mi
    numberOfDays: 2
    podAnnotations:
      sidecar.istio.io/inject: "false"
    initHook:
      annotations:
        # Needs to wait for jaeger-stack-elasticsearch secret to be created.
        # It seems a bug since this isn't supposed to be set.
        "helm.sh/hook": post-install,post-upgrade
      podAnnotations:
        sidecar.istio.io/inject: "false"

  # Refreshes indexes. Know more in https://www.elastic.co/guide/en/elasticsearch/reference/current/index-rollover.html
  esRollover:
    enabled: true
    image: jaegertracing/jaeger-es-rollover
    tag: latest
    extraEnv:
      - name: CONDITIONS
        # See more in conditions field specification: https://www.elastic.co/guide/en/elasticsearch/reference/master/indices-rollover-index.html#rollover-index-api-request-body
        value: '{"max_age": "1d"}'
      # Format: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#schedule-syntax
    schedule: "10 0 * * *"
    successfulJobsHistoryLimit: 3
    failedJobsHistoryLimit: 3
    concurrencyPolicy: Forbid
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 256m
        memory: 128Mi
    numberOfDays: 2
    podAnnotations:
      sidecar.istio.io/inject: "false"
    initHook:
      annotations:
        # Needs to wait for jaeger-stack-elasticsearch secret to be created.
        # It seems a bug since this isn't supposed to be set.
        "helm.sh/hook": post-install,post-upgrade
      podAnnotations:
        sidecar.istio.io/inject: "false"

otlpSidecarCollector:
  # Requires the OpenTelemetry Operator: https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-operator
  #
  # Pods are injected if they contain the annotation:
  # sidecar.opentelemetry.io/inject: "<deployed-namespace>/<otlpSidecarCollector.name>"
  enabled: false
  name: otlp-sidecar-collector
  image: otel/opentelemetry-collector-contrib
  tag: 0.81.0
  ports:
    # Specification: https://github.com/open-telemetry/opentelemetry-operator/blob/main/docs/api.md#opentelemetrycollectorspecportsindex
    - name: otlp
      port: 4317
      protocol: TCP
      appProtocol: grpc
    - name: otlp-http
      port: 4318
      protocol: TCP
  resources:
    # Specification: https://github.com/open-telemetry/opentelemetry-operator/blob/main/docs/api.md#opentelemetrycollectorspecresources
    # Note: this doesn't use the field claims.
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 256m
      memory: 128Mi
  config:
    # Config file specification: https://opentelemetry.io/docs/collector/configuration/
    extensions:
      memory_ballast: {}
    processors:
      batch: {}
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: localhost:4317
          http:
            endpoint: localhost:4318
    exporters:
      logging: {}
      otlp:
        endpoint: http://jaeger-stack-collector.observability.svc:4317
        tls:
          insecure: true
    service:
      extensions: [ memory_ballast ]
      pipelines:
        logs:
          receivers: [ otlp ]
          processors: [ batch ]
          exporters: [ logging ]
        traces:
          receivers: [ otlp ]
          processors: [ batch ]
          exporters: [ otlp ]

otlp-independent-collector:
  # Values:
  # - https://artifacthub.io/packages/helm/opentelemetry-helm/opentelemetry-collector/0.62.0
  # - https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-collector/values.yaml
  enabled: false
  fullnameOverride: "otlp-independent-collector"
  mode: daemonset
  config:
    # Config explanation: https://opentelemetry.io/docs/collector/configuration/
    extensions:
      health_check: {} # Necessary for liveness and readiness probes.
      memory_ballast: {}
    processors:
      batch: {}
      memory_limiter: null # Managed by resources field.
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
      jaeger: null
      prometheus: null
      zipkin: null
    exporters:
      logging: {}
      otlp:
        endpoint: http://jaeger-stack-collector.observability.svc:4317
        tls:
          insecure: true
    service:
      extensions: [ health_check, memory_ballast ]
      pipelines:
        metrics: null
        logs:
          receivers: [ otlp ]
          processors: [ batch ]
          exporters: [ logging ]
        traces:
          receivers: [ otlp ]
          processors: [ batch ]
          exporters: [ otlp ]
      telemetry: null
  image:
    repository: otel/opentelemetry-collector-contrib
    tag: 0.81.0
  ports:
    otlp:
      enabled: true
      containerPort: 4317
      servicePort: 4317
      hostPort: 4317
      protocol: TCP
      appProtocol: grpc
    otlp-http:
      enabled: true
      containerPort: 4318
      servicePort: 4318
      hostPort: 4318
      protocol: TCP
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false
    metrics:
      enabled: false
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 256m
      memory: 128Mi
  podAnnotations:
    sidecar.istio.io/inject: "false"
  livenessProbe:
    initialDelaySeconds: 100 # To compensate Jaeger storage backend (it takes some time).
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    terminationGracePeriodSeconds: 10
  readinessProbe:
    initialDelaySeconds: 100 # To compensate Jaeger storage backend (it takes some time).
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 5
  service:
    enabled: true
    type: ClusterIP

grafana:
  # Values:
  # - https://artifacthub.io/packages/helm/grafana/grafana/6.57.4
  # - https://github.com/grafana/helm-charts/tree/main/charts/grafana
  enabled: true
  fullnameOverride: grafana
  # username and password will be encoded
  # automatically in grafana-user's secret.
  username: grafana
  password: changeme
  replicas: 1
  livenessProbe:
    initialDelaySeconds: 20
    periodSeconds: 10
    timeoutSeconds: 30
    failureThreshold: 10
    successThreshold: 1
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 30
    failureThreshold: 10
    successThreshold: 1
  image:
    repository: docker.io/grafana/grafana
  service:
    enabled: true
    type: ClusterIP
    port: 8080
  persistence:
    enabled: true
    type: pvc
    size: 1Gi
    # Adjust to your storage class name.
    # storageClassName: local-storage
    accessModes: [ "ReadWriteOnce" ]
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Jaeger
          type: jaeger
          url: http://jaeger-stack-query.observability.svc:8080
          isDefault: false
          access: proxy
          editable: true
  # Uncomment if you're going to use Istio Gateway.
  # grafana.ini:
  #   server:
  #     # Insert the same domain as in istio.destinationHost
  #     domain: "<destination-host>"
  #     # You can't end the path with a slash.
  #     root_url: "%(protocol)s://%(domain)s:%(http_port)s/observability/grafana"
  #     serve_from_sub_path: true
  podAnnotations:
    sidecar.istio.io/inject: "true"
  podLabels:
    version: v1
  admin:
    # The chart depends on those
    # values to create the secret.
    existingSecret: grafana-user
    userKey: username
    passwordKey: password

kube-state-metrics:
  # Values:
  # - https://artifacthub.io/packages/helm/prometheus-community/kube-state-metrics/5.8.1
  # - https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-state-metrics/values.yaml
  #
  # Note: don't change fullnameOverride and service.port since the elastic
  # agent tries to access the address kube-state-metrics:8080 by default.
  enabled: true
  fullnameOverride: kube-state-metrics
  image:
    registry: registry.k8s.io
    repository: kube-state-metrics/kube-state-metrics
    tag: v2.9.2
  replicas: 1
  service:
    type: ClusterIP
    port: 8080
  podAnnotations:
    sidecar.istio.io/inject: "false"

elastic-eck-stk:
  # Values:
  # - https://artifacthub.io/packages/helm/elastic/eck-stack/0.6.0
  # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/values.yaml
  #
  # Requires the ECK Operator: https://github.com/elastic/cloud-on-k8s/tree/main/deploy
  enabled: true
  eck-elasticsearch:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-elasticsearch/values.yaml
    enabled: true
    fullnameOverride: elasticsearch-eck-stk
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    http:
      service:
        spec:
          type: ClusterIP
      tls:
        selfSignedCertificate:
          disabled: true
    nodeSets:
      - name: masters
        count: 1
        config:
          node.roles: [ "master" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage
      - name: hot
        count: 1
        config:
          node.roles: [ "data_hot", "data_content", "ingest" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage
      - name: warm
        count: 1
        config:
          node.roles: [ "data_warm" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage
      - name: cold
        count: 1
        config:
          node.roles: [ "data_cold" ]
          # Remove/comment in a production environment (it's true by default).
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          node.store.allow_mmap: false
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            containers:
              - name: elasticsearch
                readinessProbe:
                  exec:
                    command:
                      - bash
                      - -c
                      - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                  failureThreshold: 3
                  initialDelaySeconds: 100
                  periodSeconds: 12
                  successThreshold: 1
                  timeoutSeconds: 20
                env:
                  - name: READINESS_PROBE_TIMEOUT
                    value: "10"
                resources:
                  limits:
                    cpu: 1
                    memory: 2Gi
                  requests:
                    cpu: 1
                    memory: 2Gi
              # Uncomment in a prodution environment.
              # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
              # initContainers:
              # - command:
              #   - sh
              #   - "-c"
              #   - sysctl -w vm.max_map_count=262144
              #   name: sysctl
              #   securityContext:
              #     privileged: true
              #     runAsUser: 0
        volumeClaimTemplates:
          - metadata:
              name: elasticsearch-data
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
              # Adjust to your storage class name.
              # storageClassName: local-storage

  eck-kibana:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-kibana/values.yaml
    enabled: true
    fullnameOverride: kibana
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    spec:
      count: 1
      elasticsearchRef:
        name: elasticsearch-eck-stk
      http:
        service:
          spec:
            type: ClusterIP
        tls:
          selfSignedCertificate:
            disabled: true
      podTemplate:
        metadata:
          labels:
            version: v1
          annotations:
            sidecar.istio.io/inject: "true"
        spec:
          containers:
            - name: kibana
              env:
                - name: NODE_OPTIONS
                  value: "--max-old-space-size=2048"
              resources:
                limits:
                  memory: 1Gi
                  cpu: 2
                requests:
                  memory: 1Gi
                  cpu: 1
      config:
        # This depends on the namespace where ECK stack is being deployed. 
        xpack.fleet.agents.elasticsearch.hosts:
          [
            "http://elasticsearch-eck-stk-es-http.observability.svc:9200"
          ]
        xpack.fleet.agents.fleet_server.hosts: [ "http://fleet-server-agent-http.observability.svc:8220" ]
        # Uncomment if you going to use Istio Gateway. In destination-host place
        # the same value as in istio.destinationHost. You can't end the path with
        # a slash in both fields - publicBaseUrl and basePath.
        # server.publicBaseUrl: "https://<destination-host>/observability/kibana"
        # server.basePath: "/observability/kibana"
        xpack.fleet.packages:
          - name: system
            version: latest
          - name: elastic_agent
            version: latest
          - name: fleet_server
            version: latest
          - name: kubernetes
            version: latest
        xpack.fleet.agentPolicies:
          - name: Fleet Server on ECK policy
            id: eck-fleet-server
            namespace: observability
            monitoring_enabled:
              - logs
              - metrics
            package_policies:
              - name: fleet_server-1
                id: fleet_server-1
                package:
                  name: fleet_server
          - name: Elastic Agent on ECK policy
            id: eck-agent
            namespace: observability
            monitoring_enabled:
              - logs
              - metrics
            unenroll_timeout: 900
            package_policies:
              - package:
                  name: system
                name: system-1
              - package:
                  name: kubernetes
                name: kubernetes-1

  eck-agent:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-agent/values.yaml
    enabled: true
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    fullnameOverride: elastic
    spec:
      policyID: eck-agent
      kibanaRef:
        name: kibana
      elasticsearchRefs: []
      fleetServerRef:
        name: fleet-server
      mode: fleet
      daemonSet:
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            serviceAccountName: elastic-agent
            hostNetwork: true
            dnsPolicy: ClusterFirstWithHostNet
            automountServiceAccountToken: true
            securityContext:
              runAsUser: 0

  eck-fleet-server:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-fleet-server/values.yaml
    enabled: true
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    fullnameOverride: "fleet-server"
    spec:
      policyID: eck-fleet-server
      kibanaRef:
        name: kibana
      elasticsearchRefs:
        - name: elasticsearch-eck-stk
      deployment:
        replicas: 1
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            serviceAccountName: fleet-server
            automountServiceAccountToken: true
            securityContext:
              runAsUser: 0
      http:
        service:
          spec:
            type: ClusterIP
        tls:
          selfSignedCertificate:
            disabled: true
