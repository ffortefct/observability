# Modular way to activate/deactivate sectors.
tags:
  # Jaeger stack (i.e., Injester & indexer with Kafka, Collector, Query, index cleaner and rollout CronJobs with
  # Elasticsearch as datastore), OpenTelemetry Independent Collectors (see otlp-collectors section) and Grafana.
  jaeger-components: false
  # Elasticsearch, Fleet Server, Elastic Agents, Kube State Metrics and Kibana.
  eck-components: false


# Set the gateways and hosts if you are going 
# to run a service behind the Istio Gateway.
istio:
  gateways: [] # Define this.
  kibana:
    enabled: false
    ruleName: kibana-rule
    virtualServiceName: kibana-virtual-svc
    namespace: observability
    host: kibana-kb-http.observability.svc.cluster.local
    port: 5601
    # It must to be the same as the path defined
    # in the server.basePath config field.
    path: "/observability/kibana"
    hosts: [] # Define this.


elastic-jg-stk:
  # Values:
  # - https://artifacthub.io/packages/helm/elastic/eck-stack/0.6.0
  # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/values.yaml
  #
  # Requires the ECK Operator: https://github.com/elastic/cloud-on-k8s/tree/main/deploy
  eck-elasticsearch:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-elasticsearch/values.yaml
    enable: true
    fullnameOverride: elasticsearch-jg-stk
    # Jaeger's Elasticsearch client doesn't support version 8.
    version: 7.17.11
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    http:
      service:
        spec:
          type: LoadBalancer
      tls:
        selfSignedCertificate:
          disabled: true
    nodeSets:
    - name: masters
      count: 1
      config:
        node.roles: ["master"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage
    - name: hot
      count: 1
      config:
        node.roles: ["data_hot", "data_content", "ingest"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage
    - name: warm
      count: 1
      config:
        node.roles: ["data_warm"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage
    - name: cold
      count: 1
      config:
        node.roles: ["data_cold"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage

  # Unused components.
  eck-kibana:
    enabled: false
  eck-agent:
    enabled: false
  eck-fleet-server:
    enabled: false


jaeger-stack:
  # Values:
  # - https://artifacthub.io/packages/helm/jaegertracing/jaeger/0.71.7
  # - https://github.com/jaegertracing/helm-charts/blob/main/charts/jaeger/values.yaml
  #
  # Overall architecture with a brief explanation: https://www.jaegertracing.io/docs/1.46/architecture/
  provisionDataStore:
    kafka: true
    cassandra: false
    elasticsearch: false
  fullnameOverride: jaeger-stack
  storage:
    type: elasticsearch
    elasticsearch:
      host: elasticsearch-jg-stk-es-http.observability.svc
      port: 9200
      user: elastic
      usePassword: true
      existingSecret: elasticsearch-jg-stk-es-elastic-user
      existingSecretKey: elastic
      tls:
        enabled: false
    kafka:
      brokers:
        - kafka-tracing.observability.svc:9092
      topic: jaeger-tracing
      authentication: none

  # Used as an offloader in cases which the throughput of traces is higher.
  kafka:
    # Values:
    # - https://artifacthub.io/packages/helm/bitnami/kafka/19.1.5
    # - https://github.com/bitnami/charts/tree/main/bitnami/kafka
    fullnameOverride: kafka-tracing
    image:
      registry: docker.io
      repository: bitnami/kafka
      tag: 3.3.1-debian-11-r19
    replicaCount: 1
    livenessProbe:
      enabled: true
      initialDelaySeconds: 60
      timeoutSeconds: 5
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
    readinessProbe:
      enabled: true
      initialDelaySeconds: 50
      failureThreshold: 6
      timeoutSeconds: 5
      periodSeconds: 10
      successThreshold: 1
    podAnnotations:
      sidecar.istio.io/inject: "false"
    autoCreateTopicsEnable: true
    externalAccess:
      service:
        type: LoadBalancer
    persistence:
      enabled: true
      # Adjust to your storage class name.
      # storageClass: local-storage
      accessModes: ["ReadWriteOnce"]
      size: 1Gi
      logPersistence:
        enabled: false
        # Adjust to your storage class name.
        # storageClass: local-storage
        accessModes: ["ReadWriteOnce"]
        size: 1Gi
    zookeeper:
      # Values:
      # - https://artifacthub.io/packages/helm/bitnami/zookeeper/10.2.5
      # - https://github.com/bitnami/charts/tree/main/bitnami/zookeeper
      enabled: true
      image:
        registry: docker.io
        repository: bitnami/zookeeper
        tag: 3.8.0-debian-11-r56
      fullnameOverride: zookeeper-kafka-tracing
      replicaCount: 1
      livenessProbe:
        enabled: true
        initialDelaySeconds: 40
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 6
        successThreshold: 1
        probeCommandTimeout: 2
      readinessProbe:
        enabled: true
        initialDelaySeconds: 30
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 6
        successThreshold: 1
        probeCommandTimeout: 2
      podAnnotations:
        sidecar.istio.io/inject: "false"
      persistence:
        enabled: true
        accessModes: ["ReadWriteOnce"]
        size: 1Gi
        dataLogDir:
          size: 200Mi

  # Injests traces from Kafka to the storage backend (i.e., Elasticsearch).
  injester:
    enabled: true
    replicaCount: 1
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 2
      behavior:
        targetCPUUtilizationPercentage: 80
        targetMemoryUtilizationPercentage: 80
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
    podAnnotations:
      sidecar.istio.io/inject: "false"

  agent:
    # OpenTelemetry Collectors are used as span injestors.
    # Actually, this is deprecated...
    enabled: false

  # Recieves traces and publishes them in Kafka.
  collector:
    enabled: true
    image: jaegertracing/jaeger-collector
    tag: 1.45.0
    replicaCount: 1
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 2
    service:
      type: LoadBalancer
      otlp:
        grpc:
          name: otlp-grpc
          port: 4317
        http:
          name: otlp-http
          port: 4318
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
    podAnnotations:
      sidecar.istio.io/inject: "false"

  # Tracer viewer (with Jaeger UI included).
  # Know more here: https://www.jaegertracing.io/docs/1.6/deployment/#query-service--ui
  query:
    enabled: true
    image: jaegertracing/jaeger-query
    tag: 1.45.0
    agentSidecar:
      enabled: false
    replicaCount: 1
    service:
      type: LoadBalancer
      port: 8080
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
         cpu: 256m
         memory: 128Mi
    podAnnotations:
      sidecar.istio.io/inject: "false"

  # Kind of a garbage collector.
  esIndexCleaner:
    enabled: true
    extraEnv:
    - name: ROLLOVER
      value: 'true'
    # Format: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#schedule-syntax
    schedule: "55 23 * * *"
    successfulJobsHistoryLimit: 3
    failedJobsHistoryLimit: 3
    concurrencyPolicy: Forbid
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 256m
        memory: 128Mi
    numberOfDays: 2
    podAnnotations:
      sidecar.istio.io/inject: "false"
    initHook:
      annotations:
        # Needs to wait for jaeger-stack-elasticsearch secret to be created.
        # It seems a bug since this isn't supposed to be set this way.
        "helm.sh/hook": post-install,post-upgrade
      podAnnotations:
        sidecar.istio.io/inject: "false"

  # Refreshes indexes. Know more in https://www.elastic.co/guide/en/elasticsearch/reference/current/index-rollover.html
  esRollover:
    enabled: true
    image: jaegertracing/jaeger-es-rollover
    tag: latest
    extraEnv:
    - name: CONDITIONS
      value: '{"max_age": "1d"}'
    # Format: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#schedule-syntax
    schedule: "10 0 * * *"
    successfulJobsHistoryLimit: 3
    failedJobsHistoryLimit: 3
    concurrencyPolicy: Forbid
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 256m
        memory: 128Mi
    numberOfDays: 2
    podAnnotations:
      sidecar.istio.io/inject: "false"
    initHook:
      annotations:
        # Needs to wait for jaeger-stack-elasticsearch secret to be created.
        # It seems a bug since this isn't supposed to be set this way.
        "helm.sh/hook": post-install,post-upgrade
      podAnnotations:
        sidecar.istio.io/inject: "false"


otlpSidecarCollector:
  # Requires the OpenTelemetry Operator: https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-operator
  #
  # Pods are injected if they contain the annotation:
  # sidecar.opentelemetry.io/inject: "<deployed-namespace>/<otlpSidecarCollector.name>"
  enabled: false
  name: otlp-sidecar-collector
  image: otel/opentelemetry-collector-contrib
  tag: 0.81.0
  ports:
    # Specification: https://github.com/open-telemetry/opentelemetry-operator/blob/main/docs/api.md#opentelemetrycollectorspecportsindex
  - name: otlp
    port: 4317
    protocol: TCP
    appProtocol: grpc
  - name: otlp-http
    port: 4318
    protocol: TCP
  resources:
    # Specification: https://github.com/open-telemetry/opentelemetry-operator/blob/main/docs/api.md#opentelemetrycollectorspecresources
    # Note: this doesn't use the field claims.
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 256m
      memory: 128Mi
  config:
    # Config file specification: https://opentelemetry.io/docs/collector/configuration/
    extensions:
      memory_ballast: {}
    processors:
      batch: {}
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: localhost:4317
          http:
            endpoint: localhost:4318
    exporters:
      logging: {}
      otlp:
        endpoint: http://jaeger-stack-collector.observability.svc:4317
        tls:
          insecure: true
    service:
      extensions: [memory_ballast]
      pipelines:
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [logging]
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp]


otlp-collector:
  # Values:
  # - https://artifacthub.io/packages/helm/opentelemetry-helm/opentelemetry-collector/0.62.0
  # - https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-collector/values.yaml
  enabled: false
  fullnameOverride: "otlp-independent-collector"
  mode: daemonset
  config:
    # Config explanation: https://opentelemetry.io/docs/collector/configuration/
    extensions:
      health_check: {} # Necessary for liveness and readiness probes.
      memory_ballast: {}
    processors:
      batch: {}
      memory_limiter: null # Managed by resources field.
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
      jaeger: null
      prometheus: null
      zipkin: null
    exporters:
      logging: {}
      otlp:
        endpoint: http://jaeger-stack-collector.observability.svc:4317
        tls:
          insecure: true
    service:
      extensions: [health_check, memory_ballast]
      pipelines:
        metrics: null
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [logging]
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp]
      telemetry: null
  image:
    repository: otel/opentelemetry-collector-contrib
    tag: 0.81.0
  ports:
    otlp:
      enabled: true
      containerPort: 4317
      servicePort: 4317
      hostPort: 4317
      protocol: TCP
      appProtocol: grpc
    otlp-http:
      enabled: true
      containerPort: 4318
      servicePort: 4318
      hostPort: 4318
      protocol: TCP
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 256m
      memory: 128Mi
  podAnnotations:
    sidecar.istio.io/inject: "false"
  livenessProbe:
    initialDelaySeconds: 100 # To compensate Jaeger storage backend (it takes some time).
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    terminationGracePeriodSeconds: 10
  readinessProbe:
    initialDelaySeconds: 100 # To compensate Jaeger storage backend (it takes some time).
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 5
  service:
    enabled: true
    # Don't change to LoadBalancer, unless
    # you pretend to use the deployment mode.
    type: ClusterIP


kube-state-metrics:
  # Values:
  # - https://artifacthub.io/packages/helm/prometheus-community/kube-state-metrics/5.8.1
  # - https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-state-metrics/values.yaml
  fullnameOverride: kube-state-metrics
  image:
    registry: registry.k8s.io
    repository: kube-state-metrics/kube-state-metrics
    tag: v2.9.2
  replicas: 1
  service:
    type: ClusterIP
    port: 8080
  podAnnotations:
    sidecar.istio.io/inject: "false"


elastic-eck-stk:
  # Values:
  # - https://artifacthub.io/packages/helm/elastic/eck-stack/0.6.0
  # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/values.yaml
  #
  # Requires the ECK Operator: https://github.com/elastic/cloud-on-k8s/tree/main/deploy
  eck-elasticsearch:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-elasticsearch/values.yaml
    enable: true
    fullnameOverride: elasticsearch-eck-stk
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    http:
      service:
        spec:
          type: LoadBalancer
      tls:
        selfSignedCertificate:
          disabled: true
    nodeSets:
    - name: masters
      count: 1
      config:
        node.roles: ["master"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage
    - name: hot
      count: 1
      config:
        node.roles: ["data_hot", "data_content", "ingest"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage
    - name: warm
      count: 1
      config:
        node.roles: ["data_warm"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage
    - name: cold
      count: 1
      config:
        node.roles: ["data_cold"]
        # Remove/comment in a production environment (it's true by default).
        # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          annotations:
            sidecar.istio.io/inject: "false"
        spec:
          containers:
          - name: elasticsearch
            readinessProbe:
              exec:
                command:
                - bash
                - -c
                - /mnt/elastic-internal/scripts/readiness-probe-script.sh
              failureThreshold: 3
              initialDelaySeconds: 100
              periodSeconds: 12
              successThreshold: 1
              timeoutSeconds: 20
            env:
            - name: READINESS_PROBE_TIMEOUT
              value: "10"
            resources:
              limits:
                cpu: 1
                memory: 2Gi
              requests:
                cpu: 1
                memory: 2Gi
          # Uncomment in a prodution environment.
          # Please read this: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html 
          # initContainers:
          # - command:
          #   - sh
          #   - "-c"
          #   - sysctl -w vm.max_map_count=262144
          #   name: sysctl
          #   securityContext:
          #     privileged: true
          #     runAsUser: 0   
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          # Adjust to your storage class name.
          # storageClassName: local-storage

  eck-kibana:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-kibana/values.yaml
    enabled: true
    fullnameOverride: kibana
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    spec:
      count: 1
      elasticsearchRef:
        name: elasticsearch-eck-stk
      http:
        service:
          spec:
            type: LoadBalancer
        tls:
          selfSignedCertificate:
            disabled: true
      podTemplate:
        metadata:
          labels:
            version: v1
          annotations:
            sidecar.istio.io/inject: "true"
        spec:
          containers:
          - name: kibana
            env:
            - name: NODE_OPTIONS
              value: "--max-old-space-size=2048"
            resources:
              limits:
                memory: 1Gi
                cpu: 2
              requests:
                memory: 1Gi
                cpu: 1
      config:
        # This depends on the namespace where ECK stack is being deployed. 
        xpack.fleet.agents.elasticsearch.hosts: ["http://elasticsearch-eck-stk-es-http.observability.svc:9200"]
        xpack.fleet.agents.fleet_server.hosts: ["http://fleet-server-agent-http.observability.svc:8220"]
        # Uncomment if you going to use Istio Gateway.
        # server.basePath: "/observability/kibana"
        xpack.fleet.packages:
        - name: system
          version: latest
        - name: elastic_agent
          version: latest
        - name: fleet_server
          version: latest
        - name: kubernetes
          version: latest
        xpack.fleet.agentPolicies:
        - name: Fleet Server on ECK policy
          id: eck-fleet-server
          namespace: observability
          monitoring_enabled:
          - logs
          - metrics
          package_policies:
          - name: fleet_server-1
            id: fleet_server-1
            package:
              name: fleet_server
        - name: Elastic Agent on ECK policy
          id: eck-agent
          namespace: observability
          monitoring_enabled:
          - logs
          - metrics
          unenroll_timeout: 900
          package_policies:
          - package:
              name: system
            name: system-1
          - package:
              name: kubernetes
            name: kubernetes-1

  eck-agent:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-agent/values.yaml
    enabled: true
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    fullnameOverride: elastic
    spec:
      policyID: eck-agent
      kibanaRef:
        name: kibana
      elasticsearchRefs: []
      fleetServerRef:
        name: fleet-server
      mode: fleet
      daemonSet:
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            serviceAccountName: elastic-agent
            hostNetwork: true
            dnsPolicy: ClusterFirstWithHostNet
            automountServiceAccountToken: true
            securityContext:
              runAsUser: 0

  eck-fleet-server:
    # Values:
    # - https://github.com/elastic/cloud-on-k8s/blob/main/deploy/eck-stack/charts/eck-fleet-server/values.yaml
    enabled: true
    version: 8.9.0-SNAPSHOT
    annotations:
      # Remove only if you're using the Elastic Enterprise.
      eck.k8s.elastic.co/license: basic
    fullnameOverride: "fleet-server"
    spec:
      policyID: eck-fleet-server
      kibanaRef:
        name: kibana
      elasticsearchRefs:
      - name: elasticsearch-eck-stk
      deployment:
        replicas: 1
        podTemplate:
          metadata:
            annotations:
              sidecar.istio.io/inject: "false"
          spec:
            serviceAccountName: fleet-server
            automountServiceAccountToken: true
            securityContext:
              runAsUser: 0
      http:
        tls:
          selfSignedCertificate:
            disabled: true

